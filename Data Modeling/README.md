# Data Modeling with Postgres

This project focuses on data modeling using Postgres and building an ETL pipeline using Python. The goal is to assist a startup in analyzing the data they have collected on songs and user activity from their new music streaming app. Currently, the data is stored in JSON format, and the analytics team is particularly interested in understanding the songs that users are listening to.

## Dataset Overview

The dataset used in this project is a subset of the Million Song Dataset, containing information about songs, artists, and user activity logs generated by an event simulator.

## Schema Design

The database schema consists of a fact table and several dimension tables.

**Fact Table:**
- songplays - Records in the log data associated with song plays (identified by the "NextSong" page).

**Dimension Tables:**
- users - Information about the users in the app.
- songs - Information about the songs in the music database.
- artists - Information about the artists in the music database.
- time - Timestamps of records in songplays, broken down into specific units.

## Project Files

- `sql_queries.py`: Contains SQL queries for dropping and creating the fact and dimension tables. It also includes insertion query templates.
- `create_tables.py`: Sets up the database. Running this file creates the sparkifydb database and creates the fact and dimension tables.
- `etl.ipynb`: Jupyter Notebook for analyzing the dataset before loading.
- `etl.py`: Reads and processes song_data and log_data, populating the fact and dimension tables.
- `test.ipynb`: Jupyter Notebook to connect to the Postgres database and validate the loaded data.

## Environment

- Python 3.6 or above
- PostgreSQL 9.5 or above
- psycopg2 - PostgreSQL database adapter for Python

## How to Run

1. Run the main program `main.py` using the following command:
```
python main.py
``` 

2. Alternatively, you can run the `create_tables.py` and `etl.py` files independently:
```
python create_tables.py 
python etl.py 
```

Make sure to have Python, PostgresSQL, and psycopg2 installed to execute the code successfully.

